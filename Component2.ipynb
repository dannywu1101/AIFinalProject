{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7260be",
   "metadata": {},
   "source": [
    "## Component Two: Vehicle Damage Insurance Claim Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edcb1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92869cc9",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2202e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already in directory: /Users/dannywu/Library/CloudStorage/OneDrive-hull.ac.uk/AI/FinalProject\n",
      "\n",
      "Checking files...\n",
      "Train CSV: /Users/dannywu/Library/CloudStorage/OneDrive-hull.ac.uk/AI/FinalProject/train/train.csv\n",
      "  Exists: True\n",
      "Test CSV: /Users/dannywu/Library/CloudStorage/OneDrive-hull.ac.uk/AI/FinalProject/test/test.csv\n",
      "  Exists: True\n",
      "\n",
      "Loading CSV files...\n",
      "Training data shape: (7200, 3)\n",
      "Test data shape: (4800, 2)\n",
      "\n",
      "Unique labels: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6)]\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "1     171\n",
      "2    2349\n",
      "3     534\n",
      "4    2079\n",
      "5    1185\n",
      "6     882\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id filename  label\n",
       "0         1    1.jpg      2\n",
       "1         2    2.jpg      4\n",
       "2         3    3.jpg      2\n",
       "3         4    4.jpg      3\n",
       "4         5    5.jpg      5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the project directory (FinalProject folder)\n",
    "project_dir = '/Users/dannywu/Library/CloudStorage/OneDrive-hull.ac.uk/AI/FinalProject'\n",
    "\n",
    "# Change to project directory\n",
    "if os.getcwd() != project_dir:\n",
    "    os.chdir(project_dir)\n",
    "    print(f\"Changed to directory: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Already in directory: {os.getcwd()}\")\n",
    "\n",
    "# Define file paths\n",
    "train_path = os.path.join(project_dir, 'train', 'train.csv')\n",
    "test_path = os.path.join(project_dir, 'test', 'test.csv')\n",
    "\n",
    "# Verify files exist before loading\n",
    "print(f\"\\nChecking files...\")\n",
    "print(f\"Train CSV: {train_path}\")\n",
    "print(f\"  Exists: {os.path.exists(train_path)}\")\n",
    "print(f\"Test CSV: {test_path}\")\n",
    "print(f\"  Exists: {os.path.exists(test_path)}\")\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(f\"Train CSV not found at: {train_path}\")\n",
    "if not os.path.exists(test_path):\n",
    "    raise FileNotFoundError(f\"Test CSV not found at: {test_path}\")\n",
    "\n",
    "# Load CSV files to understand the data structure\n",
    "print(\"\\nLoading CSV files...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nUnique labels:\", sorted(train_df['label'].unique()))\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(train_df['label'].value_counts().sort_index())\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23edd81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming class directories to meaningful names...\n",
      "  'crack' already exists\n",
      "  'scratch' already exists\n",
      "  'tire_flat' already exists\n",
      "  'dent' already exists\n",
      "  'glass_shatter' already exists\n",
      "  'lamp_broken' already exists\n",
      "\n",
      "Final class directories:\n",
      "  crack: 171 images\n",
      "  dent: 2079 images\n",
      "  glass_shatter: 1185 images\n",
      "  lamp_broken: 882 images\n",
      "  scratch: 2349 images\n",
      "  tire_flat: 534 images\n"
     ]
    }
   ],
   "source": [
    "# Rename existing class directories to meaningful names (if already organized)\n",
    "organized_dir = 'organized_data'\n",
    "\n",
    "# Define meaningful class names for vehicle damage categories\n",
    "class_name_mapping = {\n",
    "    '1': 'crack',\n",
    "    '2': 'scratch',\n",
    "    '3': 'tire_flat',\n",
    "    '4': 'dent',\n",
    "    '5': 'glass_shatter',\n",
    "    '6': 'lamp_broken'\n",
    "}\n",
    "\n",
    "if os.path.exists(organized_dir):\n",
    "    print(\"Renaming class directories to meaningful names...\")\n",
    "    \n",
    "    for old_label, new_name in class_name_mapping.items():\n",
    "        old_path = os.path.join(organized_dir, old_label)\n",
    "        new_path = os.path.join(organized_dir, new_name)\n",
    "        \n",
    "        if os.path.exists(old_path) and not os.path.exists(new_path):\n",
    "            os.rename(old_path, new_path)\n",
    "            img_count = len([f for f in os.listdir(new_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"  Renamed '{old_label}' -> '{new_name}' ({img_count} images)\")\n",
    "        elif os.path.exists(new_path):\n",
    "            print(f\"  '{new_name}' already exists\")\n",
    "    \n",
    "    print(\"\\nFinal class directories:\")\n",
    "    for class_dir in sorted(os.listdir(organized_dir)):\n",
    "        class_path = os.path.join(organized_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            img_count = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"  {class_dir}: {img_count} images\")\n",
    "else:\n",
    "    print(\"organized_data directory does not exist. Run Cell 4 first to organize images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f68a5a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing images into class subdirectories...\n",
      "  Processed 1000/7200 images...\n",
      "  Processed 2000/7200 images...\n",
      "  Processed 3000/7200 images...\n",
      "  Processed 4000/7200 images...\n",
      "  Processed 5000/7200 images...\n",
      "  Processed 6000/7200 images...\n",
      "  Processed 7000/7200 images...\n",
      "\n",
      "Completed! Images organized into 6 class directories\n",
      "\n",
      "Class directories created:\n",
      "  crack: 171 images\n",
      "  dent: 2079 images\n",
      "  glass_shatter: 1185 images\n",
      "  lamp_broken: 882 images\n",
      "  scratch: 2349 images\n",
      "  tire_flat: 534 images\n"
     ]
    }
   ],
   "source": [
    "# Organize images into class subdirectories (required for image_dataset_from_directory)\n",
    "organized_dir = 'organized_data'\n",
    "\n",
    "# Define meaningful class names for vehicle damage categories\n",
    "class_name_mapping = {\n",
    "    '1': 'crack',\n",
    "    '2': 'scratch',\n",
    "    '3': 'tire_flat',\n",
    "    '4': 'dent',\n",
    "    '5': 'glass_shatter',\n",
    "    '6': 'lamp_broken'\n",
    "}\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists(organized_dir):\n",
    "    shutil.rmtree(organized_dir)\n",
    "\n",
    "os.makedirs(organized_dir, exist_ok=True)\n",
    "\n",
    "# Copy images to class subdirectories with meaningful names\n",
    "print(\"Organizing images into class subdirectories...\")\n",
    "for idx, row in train_df.iterrows():\n",
    "    label = str(row['label'])\n",
    "    class_name = class_name_mapping.get(label, f'class_{label}')\n",
    "    filename = row['filename']\n",
    "    src = os.path.join(project_dir, 'train', 'images', filename)\n",
    "    dst_dir = os.path.join(organized_dir, class_name)\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    dst = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(train_df)} images...\")\n",
    "\n",
    "print(f\"\\nCompleted! Images organized into {len(os.listdir(organized_dir))} class directories\")\n",
    "print(\"\\nClass directories created:\")\n",
    "for class_dir in sorted(os.listdir(organized_dir)):\n",
    "    class_path = os.path.join(organized_dir, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        img_count = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"  {class_dir}: {img_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a21ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images in organized_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 files belonging to 6 classes.\n",
      "Using 6480 files for training.\n",
      "Found 7200 files belonging to 6 classes.\n",
      "Using 720 files for validation.\n",
      "Class names: ['crack', 'dent', 'glass_shatter', 'lamp_broken', 'scratch', 'tire_flat']\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Load images using image_dataset_from_directory (as per workshop instructions)\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# Check if organized_data directory exists\n",
    "if not os.path.exists(organized_dir):\n",
    "    print(f\"ERROR: {organized_dir} directory does not exist!\")\n",
    "    print(\"Please run the previous cell (Cell 4) to organize images first.\")\n",
    "else:\n",
    "    # Count images to verify\n",
    "    total_images = 0\n",
    "    for class_dir in os.listdir(organized_dir):\n",
    "        class_path = os.path.join(organized_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            img_count = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            total_images += img_count\n",
    "    \n",
    "    print(f\"Found {total_images} images in {organized_dir}\")\n",
    "    \n",
    "    if total_images == 0:\n",
    "        print(\"ERROR: No images found! Please run Cell 4 to organize images.\")\n",
    "    elif total_images < len(train_df):\n",
    "        print(f\"WARNING: Only {total_images} images found, expected {len(train_df)}\")\n",
    "        print(\"The organization may not be complete. Please run Cell 4 again.\")\n",
    "    else:\n",
    "        data_dir = organized_dir\n",
    "        \n",
    "        # Load training dataset with 10% validation split\n",
    "        train_ds = image_dataset_from_directory(\n",
    "            data_dir,\n",
    "            validation_split=0.1,\n",
    "            subset=\"training\",\n",
    "            seed=42,\n",
    "            batch_size=None\n",
    "        )\n",
    "        \n",
    "        # Load validation dataset\n",
    "        val_ds = image_dataset_from_directory(\n",
    "            data_dir,\n",
    "            validation_split=0.1,\n",
    "            subset=\"validation\",\n",
    "            seed=42,\n",
    "            batch_size=None\n",
    "        )\n",
    "        \n",
    "        print(\"Class names:\", train_ds.class_names)\n",
    "        print(\"Number of classes:\", len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc6906ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (6480, 256, 256, 3)\n",
      "Training labels shape: (6480,)\n",
      "Image dtype: uint8\n",
      "Label dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Extract images and labels into NumPy arrays (as per workshop instructions)\n",
    "x_train = []\n",
    "y_train = []\n",
    "for x, y in train_ds:\n",
    "    x_train.append(np.uint8(x.numpy()))\n",
    "    y_train.append(y.numpy())\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Image dtype:\", x_train.dtype)\n",
    "print(\"Label dtype:\", y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90cead2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data shape: (720, 256, 256, 3)\n",
      "Validation labels shape: (720,)\n"
     ]
    }
   ],
   "source": [
    "# Extract validation images and labels\n",
    "x_val = []\n",
    "y_val = []\n",
    "for x, y in val_ds:\n",
    "    x_val.append(np.uint8(x.numpy()))\n",
    "    y_val.append(y.numpy())\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(\"Validation data shape:\", x_val.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images found: 4800\n",
      "Test images will be loaded when needed for predictions\n",
      "First few test filenames: ['7201.jpg', '7202.jpg', '7203.jpg', '7204.jpg', '7205.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Load test images (test set has no labels)\n",
    "# Note: Images will be loaded when needed for predictions\n",
    "# For now, we'll just store the filenames\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "test_filenames = []\n",
    "test_image_paths = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    img_path = os.path.join(project_dir, 'test', 'images', filename)\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        test_filenames.append(filename)\n",
    "        test_image_paths.append(img_path)\n",
    "\n",
    "print(f\"Test images found: {len(test_filenames)}\")\n",
    "print(f\"Test images will be loaded when needed for predictions\")\n",
    "print(f\"First few test filenames: {test_filenames[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7037446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Dataset Summary\n",
      "==================================================\n",
      "Training images: 6480\n",
      "Validation images: 720\n",
      "Test images: 4800 (filenames stored)\n",
      "\n",
      "Image shape: (256, 256, 3)\n",
      "Number of classes: 6\n",
      "Class names: ['crack', 'dent', 'glass_shatter', 'lamp_broken', 'scratch', 'tire_flat']\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\"*50)\n",
    "print(\"Dataset Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training images: {x_train.shape[0]}\")\n",
    "print(f\"Validation images: {x_val.shape[0]}\")\n",
    "print(f\"Test images: {len(test_filenames)} (filenames stored)\")\n",
    "print(f\"\\nImage shape: {x_train.shape[1:]}\")\n",
    "print(f\"Number of classes: {len(train_ds.class_names)}\")\n",
    "print(f\"Class names: {train_ds.class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1d101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
